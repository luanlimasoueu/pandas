{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  22000   30days    1000.0\n",
      "1  PySpark  25000   50days    2300.0\n",
      "2   Hadoop  23000   55days    1500.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "technologies = [\n",
    "            (\"Spark\", 22000,'30days',1000.0),\n",
    "            (\"PySpark\",25000,'50days',2300.0),\n",
    "            (\"Hadoop\",23000,'55days',1500.0)\n",
    "            ]\n",
    "df = pd.DataFrame(technologies,columns = ['Courses','Fee','Duration','Discount'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Spark\n",
      "1    PySpark\n",
      "2     Hadoop\n",
      "Name: Courses, dtype: object\n",
      "0    22000\n",
      "1    25000\n",
      "2    23000\n",
      "Name: Fee, dtype: int64\n",
      "0    30days\n",
      "1    50days\n",
      "2    55days\n",
      "Name: Duration, dtype: object\n",
      "0    1000.0\n",
      "1    2300.0\n",
      "2    1500.0\n",
      "Name: Discount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for column in df:\n",
    "    print(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spark' 'PySpark' 'Hadoop']\n",
      "[22000 25000 23000]\n",
      "['30days' '50days' '55days']\n",
      "[1000. 2300. 1500.]\n"
     ]
    }
   ],
   "source": [
    "for column in df:\n",
    "    print(df[column].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses ['Spark' 'PySpark' 'Hadoop']\n",
      "Fee [22000 25000 23000]\n",
      "Duration ['30days' '50days' '55days']\n",
      "Discount [1000. 2300. 1500.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luan Lima\\AppData\\Local\\Temp\\ipykernel_23008\\3658610266.py:1: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for (colname,colval) in df.iteritems():\n"
     ]
    }
   ],
   "source": [
    "for (colname,colval) in df.iteritems():\n",
    "    print(colname, colval.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses: PySpark\n",
      "Fee: 25000\n",
      "Duration: 50days\n",
      "Discount: 2300.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luan Lima\\AppData\\Local\\Temp\\ipykernel_23008\\2997700347.py:1: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for name, values in df.iteritems():\n"
     ]
    }
   ],
   "source": [
    "for name, values in df.iteritems():\n",
    "   print('{name}: {value}'.format(name=name, value=values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['Spark' 'PySpark' 'Hadoop']\n",
      "1 [22000 25000 23000]\n",
      "2 ['30days' '50days' '55days']\n",
      "3 [1000. 2300. 1500.]\n"
     ]
    }
   ],
   "source": [
    "for (index, colname) in enumerate(df):\n",
    "    print(index, df[colname].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0      Spark\n",
      "1    PySpark\n",
      "2     Hadoop\n",
      "Name: Courses, dtype: object\n",
      "1 0    22000\n",
      "1    25000\n",
      "2    23000\n",
      "Name: Fee, dtype: int64\n",
      "2 0    30days\n",
      "1    50days\n",
      "2    55days\n",
      "Name: Duration, dtype: object\n",
      "3 0    1000.0\n",
      "1    2300.0\n",
      "2    1500.0\n",
      "Name: Discount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for (index, column) in enumerate(df):\n",
    "    print (index, df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['Spark' 'PySpark' 'Hadoop']\n",
      "1 [22000 25000 23000]\n",
      "2 ['30days' '50days' '55days']\n",
      "3 [1000. 2300. 1500.]\n"
     ]
    }
   ],
   "source": [
    "for (index, column) in enumerate(df):\n",
    "    print (index, np.asarray(df[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22000\n",
      "1    25000\n",
      "2    23000\n",
      "Name: Fee, dtype: int64\n",
      "0    30days\n",
      "1    50days\n",
      "2    55days\n",
      "Name: Duration, dtype: object\n",
      "0    1000.0\n",
      "1    2300.0\n",
      "2    1500.0\n",
      "Name: Discount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns[1:]:\n",
    "    print(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1000.0\n",
      "1    2300.0\n",
      "2    1500.0\n",
      "Name: Discount, dtype: float64\n",
      "0    30days\n",
      "1    50days\n",
      "2    55days\n",
      "Name: Duration, dtype: object\n",
      "0    22000\n",
      "1    25000\n",
      "2    23000\n",
      "Name: Fee, dtype: int64\n",
      "0      Spark\n",
      "1    PySpark\n",
      "2     Hadoop\n",
      "Name: Courses, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns[::-1]:\n",
    "    print(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Courses\n",
      "1 Fee\n",
      "2 Duration\n",
      "3 Discount\n"
     ]
    }
   ],
   "source": [
    "for indix, column in enumerate(df.columns):\n",
    "    print(indix, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses\n",
      "Fee\n",
      "Duration\n",
      "Discount\n"
     ]
    }
   ],
   "source": [
    "for (column_name, column) in df.transpose().iterrows():\n",
    "    print (column_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
